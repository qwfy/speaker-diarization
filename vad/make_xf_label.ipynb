{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "root = '/home/incomplete/ai/'\n",
    "project_root = os.path.join(root, 'speaker-diarization')\n",
    "\n",
    "os.chdir(project_root)\n",
    "import sys\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import result.rttm\n",
    "import rttm_tools\n",
    "from typing import List, Tuple, Dict, Optional"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing result/vad_xf/F_clean_hdgs.wav.transcript.json\n",
      "processing result/vad_xf/M_clean_yztj.wav.transcript.json\n",
      "processing result/vad_xf/M_echo_sjzm.wav.transcript.json\n"
     ]
    }
   ],
   "source": [
    "PUNCTUATIONS = ' 。，？！、'\n",
    "\n",
    "# reviewed\n",
    "def find_labels(start_seconds, stop_seconds, rttms):\n",
    "    intersections = []\n",
    "    for rttm in rttms:\n",
    "        parts = result.rttm.intersection(start_seconds, stop_seconds, 'l', rttm.start, rttm.stop, 'r')\n",
    "        if parts is None:\n",
    "            continue\n",
    "        else:\n",
    "            for (istart, istop, tag) in parts:\n",
    "                if tag == 'intersection':\n",
    "                    intersections.append((istop - istart, (istart, istop), rttm.speaker))\n",
    "    intersections.sort(key=lambda x: x[0], reverse=True)\n",
    "    if intersections:\n",
    "        return intersections\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "MERGE_THRESHOLD_MS = 250\n",
    "\n",
    "# reviewed\n",
    "def pick_words_of_speaker(words_with_labels, speaker) -> List[Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Filter words of speaker, keep the longest duration, result in seconds\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for _word, labels in words_with_labels:\n",
    "        labels = [\n",
    "            ends\n",
    "            for _duration, ends, label in sorted(labels, reverse=True)\n",
    "            if label == speaker\n",
    "        ]\n",
    "        if labels:\n",
    "            start_s, stop_s = labels[0]\n",
    "            res.append((start_s * 1000, stop_s * 1000))\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "# obtain label from human annotation\n",
    "for path in glob('result/vad_xf/*.transcript.json'):\n",
    "    print('processing', path)\n",
    "    with open(path) as f:\n",
    "        sentences = json.load(f)\n",
    "\n",
    "    # load human labels\n",
    "    basename = os.path.basename(path)\n",
    "    file_id = basename.split('.')[0]\n",
    "    rttm_path = os.path.join('result/label_rttm_raw', f'{file_id}.rttm')\n",
    "    rttms = result.rttm.load_rttm(rttm_path)\n",
    "\n",
    "    word_id = 0\n",
    "    words_dropped = set()\n",
    "    # tag each word with speaker,\n",
    "    # words with no speaker information are dropped\n",
    "    words_with_labels = []\n",
    "    for sent in sentences:\n",
    "        for word in sent['words']:\n",
    "            word['id'] = word_id\n",
    "            word_id += 1\n",
    "            # punctuations are ignored\n",
    "            if word['text'] in PUNCTUATIONS:\n",
    "                words_dropped.add(word['id'])\n",
    "                continue\n",
    "            w_start = word['start_ms_audio_time']\n",
    "            w_stop = word['stop_ms_audio_time']\n",
    "            # if the word is labeled, then keep it,\n",
    "            # otherwise drop it\n",
    "            labels = find_labels(w_start/1000, w_stop/1000, rttms)\n",
    "            if labels:\n",
    "                # labels = list(set([lbl for _, lbl in labels]))\n",
    "                words_with_labels.append((word, labels))\n",
    "            else:\n",
    "                # words with no labels are dropped\n",
    "                words_dropped.add(word['id'])\n",
    "\n",
    "    # sanity check\n",
    "    old_len = np.sum([len(x['words']) for x in sentences])\n",
    "    new_len = len(words_with_labels) + len(words_dropped)\n",
    "    assert old_len == new_len\n",
    "\n",
    "    all_labels = set(\n",
    "        [label\n",
    "         for _word, labels in words_with_labels\n",
    "         for _duration, _ends, label in labels\n",
    "        ]\n",
    "    )\n",
    "    # sanity check\n",
    "    assert all_labels == set(['s', 't'])\n",
    "\n",
    "    # t_words = [\n",
    "    #     (w['start_ms_audio_time'], w['stop_ms_audio_time'])\n",
    "    #     for w, labels in words_with_labels\n",
    "    #     if 't' in labels\n",
    "    # ]\n",
    "    # s_words = [\n",
    "    #     (w['start_ms_audio_time'], w['stop_ms_audio_time'])\n",
    "    #     for w, labels in words_with_labels\n",
    "    #     if 's' in labels\n",
    "    # ]\n",
    "    t_words = pick_words_of_speaker(words_with_labels, 't')\n",
    "    s_words = pick_words_of_speaker(words_with_labels, 's')\n",
    "    # sanity check\n",
    "    # pigeon hole\n",
    "    assert len(t_words) + len(s_words) >= len(words_with_labels)\n",
    "    assert len(t_words) + len(s_words) <= 2 * old_len\n",
    "    t_sents = rttm_tools.merge_intervals(\n",
    "        t_words, [], MERGE_THRESHOLD_MS\n",
    "    )\n",
    "    s_sents = rttm_tools.merge_intervals(\n",
    "        s_words, [], MERGE_THRESHOLD_MS\n",
    "    )\n",
    "    rows = []\n",
    "    for sents, tag in [(t_sents, 't'), (s_sents, 's')]:\n",
    "        for (start, stop), tag in zip(sents, itertools.repeat(tag)):\n",
    "            # remove short segs (FOR TRY ONLY)\n",
    "            if stop - start < 1500:\n",
    "                continue\n",
    "            rttm = result.rttm.Rttm(\n",
    "                file_id, start/1000, (stop-start)/1000, tag\n",
    "            )\n",
    "            rows.append(rttm)\n",
    "    rttm_out_path = os.path.join('result/label_rttm_xf', f'{file_id}.rttm')\n",
    "    result.rttm.write_rttm(rows, rttm_out_path)\n",
    "    # write label for audacity\n",
    "    result.rttm.write_tsv(\n",
    "        [\n",
    "            (r.start, r.stop, r.speaker)\n",
    "            for r in rows\n",
    "        ],\n",
    "        f'{rttm_out_path}.txt'\n",
    "    )\n",
    "\n",
    "    # make vad\n",
    "    # vad_words = [\n",
    "    #     (w['start_ms_audio_time'], w['stop_ms_audio_time'])\n",
    "    #     for w, _ in words_with_labels\n",
    "    # ]\n",
    "    # sents = rttm_tools.merge_intervals(vad_words, [], MERGE_THRESHOLD_MS)\n",
    "    # sents = [\n",
    "    #     (start/1000, stop/1000, 'v')\n",
    "    #     for start, stop in sents\n",
    "    # ]\n",
    "\n",
    "    # make vad\n",
    "    # this is insane (FOR TRY ONLY)\n",
    "    # translate the rttm directly to vad\n",
    "    sents = []\n",
    "    # here the length filtering is done before merging,\n",
    "    # to keep it in-sync with the rttm\n",
    "    sents.extend([(start, stop) for start, stop in t_sents if stop - start >= 1500])\n",
    "    sents.extend([(start, stop) for start, stop in s_sents if stop - start >= 1500])\n",
    "    sents = rttm_tools.merge_intervals(sents, [], 0)\n",
    "    sents = [\n",
    "        (start/1000, stop/1000)\n",
    "        for start, stop in sents\n",
    "    ]\n",
    "\n",
    "    vad_out_path = os.path.join('result/vad_xf', f'{file_id}.lab')\n",
    "    result.rttm.write_lab(sents, vad_out_path)\n",
    "    # write label for audacity\n",
    "    result.rttm.write_tsv(\n",
    "        [(x, y, 'v') for x, y in sents],\n",
    "        vad_out_path + '.txt'\n",
    "    )\n",
    "\n",
    "\n",
    "    # label each word\n",
    "    words = []\n",
    "    for sent in sentences:\n",
    "        for word in sent['words']:\n",
    "            words.append(\n",
    "                (\n",
    "                    word['start_ms_audio_time']/1000,\n",
    "                    word['stop_ms_audio_time']/1000,\n",
    "                    word['text']\n",
    "                )\n",
    "            )\n",
    "    result.rttm.write_tsv(words, os.path.join('result/vad_xf', f'{file_id}.word.txt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for path in glob('result/vad_xf/*.lab'):\n",
    "    lines = result.rttm.load_lab(path)\n",
    "\n",
    "    basename = os.path.basename(path)\n",
    "    file_id = basename.split('.')[0]\n",
    "\n",
    "    lengths = [\n",
    "        line[1] - line[0]\n",
    "        for line in lines\n",
    "    ]\n",
    "    # median = np.median(lengths)\n",
    "    short_threshold = 0.75\n",
    "    print(file_id, 'short_threshold', short_threshold)\n",
    "    shorts = [x for x in lengths if x < short_threshold]\n",
    "    print('counts', len(shorts), len(lengths), len(shorts)/len(lengths))\n",
    "    print('durations', np.sum(shorts), np.sum(lengths), np.sum(shorts)/np.sum(lengths))\n",
    "    print('mean duration', np.mean(lengths))\n",
    "    plt.figure()\n",
    "    plt.hist(shorts, bins=100)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}